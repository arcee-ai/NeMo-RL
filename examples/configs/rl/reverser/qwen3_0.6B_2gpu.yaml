rollouts:
  group_size: 16

  # Advantage estimation settings.
  use_leave_one_out_baseline: true
  use_std_normalization: true

  max_concurrent_rollouts: null  # Number of rollouts to generate concurrently. If unspecified, uses global batch size.
  max_staleness: 1  # Maximum number of training steps that can pass between a rollout being started and consumed.

env:
  env_name: "vf_reverse_text"
  env_kwargs: {}  # Passed to load_environment().
  max_prompt_length_ratio: 1.0
  shuffle: false

policy:
  model_name: "PrimeIntellect/Qwen3-0.6B-Reverse-Text-SFT"
  max_total_sequence_length: 512

  training:
    global_num_bins: 256
    micro_batch_size: 4
    dtype: "bfloat16"
    activation_checkpointing: true
    refit_max_pack: 1000  # Maximum number of tensors to send at once during refit.
    max_grad_norm: 1.0

    parallelism:
      tp_size: 1
      ep_size: 1
      dp_replicate: 1

    optimizer:
      name: "torch.optim.AdamW"
      kwargs:
        lr: 3.0e-6
        weight_decay: 0.01
        betas: [0.9, 0.999]
        eps: 1.0e-8
        foreach: false
        fused: false
      scheduler:
        phases:
          - name: "torch.optim.lr_scheduler.ConstantLR"
            kwargs:
              factor: 1.0
              total_iters: 10000000000
        milestones: []

    loss:
      loss_fn: clipped_pg
      ratio_clip_min: 0.2
      ratio_clip_max: 0.2
      use_importance_sampling_correction: true
      disable_ppo_ratio: false

    resources:
      gpus_per_node: 1
      num_nodes: 1

  inference:
    tp_size: 1
    gpu_memory_utilization: 0.8
    dtype: "bfloat16"
    server_timeout: 6000
    sampling_args:
      temperature: 1.0
      top_p: 1.0
    resources:
      gpus_per_node: 1
      num_nodes: 1

logging:
  log_dir: "logs"
  wandb:
    project: "rlkit-grpo-dev"
    name: "debug-reverser-0.6B"
  gpu_monitoring:
    collection_interval: 10
    flush_interval: 10

checkpointing:
  enabled: true
  checkpoint_dir: "results/debug-reverser-0.6B"
  save_period: 10
  keep_top_k: 3
